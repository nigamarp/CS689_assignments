{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install transformers\n!pip3 install datasets\n!pip3 install sentencepiece\n!pip3 install seqeval\n# d808a1c335762ae67bc9777128840c0072a22f24","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-13T07:10:48.547619Z","iopub.execute_input":"2024-03-13T07:10:48.547942Z","iopub.status.idle":"2024-03-13T07:11:46.132065Z","shell.execute_reply.started":"2024-03-13T07:10:48.547914Z","shell.execute_reply":"2024-03-13T07:11:46.130935Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m629.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=a924149c43aedcae29db7a4ca0e1d8d8ec309a4484ef31446cd91e94212ba552\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:13:39.209532Z","iopub.execute_input":"2024-03-13T07:13:39.210474Z","iopub.status.idle":"2024-03-13T07:13:53.150601Z","shell.execute_reply.started":"2024-03-13T07:13:39.210429Z","shell.execute_reply":"2024-03-13T07:13:53.149409Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nCollecting accelerate\n  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.27.2\n    Uninstalling accelerate-0.27.2:\n      Successfully uninstalled accelerate-0.27.2\nSuccessfully installed accelerate-0.28.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers[torch]","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:14:05.751088Z","iopub.execute_input":"2024-03-13T07:14:05.751790Z","iopub.status.idle":"2024-03-13T07:14:18.798586Z","shell.execute_reply.started":"2024-03-13T07:14:05.751755Z","shell.execute_reply":"2024-03-13T07:14:18.797445Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.28.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Loading Dataset**","metadata":{}},{"cell_type":"code","source":"from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n\nlang='hi'\n\nraw_datasets = load_dataset('ai4bharat/naamapadam', lang)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:14:25.644880Z","iopub.execute_input":"2024-03-13T07:14:25.645238Z","iopub.status.idle":"2024-03-13T07:18:06.735419Z","shell.execute_reply.started":"2024-03-13T07:14:25.645207Z","shell.execute_reply":"2024-03-13T07:18:06.734433Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"872b1a2579b84e76bcac1ff07df7aba9"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset naamapadam_pr/hi to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/hi/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/82.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107400ffdad746f3b004e388cdaa4022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset naamapadam_pr downloaded and prepared to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/hi/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e904e34f69bb47ab8559269e2642ed54"}},"metadata":{}}]},{"cell_type":"code","source":"text_column_name = \"tokens\"\nlabel_column_name = \"ner_tags\"","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:18:11.021789Z","iopub.execute_input":"2024-03-13T07:18:11.022364Z","iopub.status.idle":"2024-03-13T07:18:11.027288Z","shell.execute_reply.started":"2024-03-13T07:18:11.022332Z","shell.execute_reply":"2024-03-13T07:18:11.026242Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(raw_datasets['test'][1])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:18:19.396578Z","iopub.execute_input":"2024-03-13T07:18:19.397552Z","iopub.status.idle":"2024-03-13T07:18:19.404109Z","shell.execute_reply.started":"2024-03-13T07:18:19.397515Z","shell.execute_reply":"2024-03-13T07:18:19.403022Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'tokens': ['शाहरुख', 'खान', 'इन', 'दिनों', 'अपनी', 'आगामी', 'फिल्म', 'जीरो', 'की', 'शूटिंग', 'में', 'व्यस्त', 'हैं', '।'], 'ner_tags': [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"features = raw_datasets[\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:18:30.050524Z","iopub.execute_input":"2024-03-13T07:18:30.050890Z","iopub.status.idle":"2024-03-13T07:18:30.055558Z","shell.execute_reply.started":"2024-03-13T07:18:30.050861Z","shell.execute_reply":"2024-03-13T07:18:30.054443Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Mapping of Classes to Integers**","metadata":{}},{"cell_type":"code","source":"label_list = features[label_column_name].feature.names\n\nlabel_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n\nprint(label_to_id)\n\nnum_labels = len(label_list)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:18:37.043963Z","iopub.execute_input":"2024-03-13T07:18:37.044594Z","iopub.status.idle":"2024-03-13T07:18:37.050835Z","shell.execute_reply.started":"2024-03-13T07:18:37.044560Z","shell.execute_reply":"2024-03-13T07:18:37.049685Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Loading INDIC-NER**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\nimport numpy as np\n\nconfig = AutoConfig.from_pretrained('ai4bharat/indicNER', num_labels=num_labels, finetuning_task='ner')\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indicNER\")\nmodel = AutoModelForTokenClassification.from_pretrained('ai4bharat/indicNER', num_labels=num_labels )","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:18:43.491535Z","iopub.execute_input":"2024-03-13T07:18:43.492343Z","iopub.status.idle":"2024-03-13T07:19:08.815425Z","shell.execute_reply.started":"2024-03-13T07:18:43.492311Z","shell.execute_reply":"2024-03-13T07:19:08.814319Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-03-13 07:18:53.442640: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-13 07:18:53.442765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-13 07:18:53.609205: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27e2322d86e34e639c1b408e184d755c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/346 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f89bdba87dcb466284706c2f6da5498a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edffad692cb141bfbefc7ac20f50b5c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e28c30b982ee40be8cb5c36a5ab10497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"196b65fd0c1249e18e4515d6714eb891"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/667M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89a865ad801e4841948a00c74f38eab5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize all texts and align the labels with them.\npadding = \"max_length\"\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[text_column_name],\n        padding=padding,\n        truncation=True,\n        max_length=512,\n        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n        is_split_into_words=True,\n    )\n    labels = []\n    for i, label in enumerate(examples[label_column_name]):\n        # print('=====')\n        # print('{} {}'.format(i,label)) #ak\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n            # ignored in the loss function.\n            if word_idx is None:\n                label_ids.append(-100)\n            # We set the label for the first token of each word.\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n            # the label_all_tokens flag.\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:19:24.401454Z","iopub.execute_input":"2024-03-13T07:19:24.402203Z","iopub.status.idle":"2024-03-13T07:19:24.410905Z","shell.execute_reply.started":"2024-03-13T07:19:24.402173Z","shell.execute_reply":"2024-03-13T07:19:24.409928Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Training Dataset**","metadata":{}},{"cell_type":"code","source":"train_dataset = raw_datasets[\"train\"]\ntrain_dataset=train_dataset.select(range(20000))\ntrain_dataset = train_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on train dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:22:42.764766Z","iopub.execute_input":"2024-03-13T07:22:42.765794Z","iopub.status.idle":"2024-03-13T07:22:50.144212Z","shell.execute_reply.started":"2024-03-13T07:22:42.765754Z","shell.execute_reply":"2024-03-13T07:22:50.143178Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on train dataset #0:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"367bd7b9ea0545dc8f646412d85616fd"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on train dataset #1:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f271e3919b5545958cf4cd74b611feb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on train dataset #2:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6e4176adf7548c4ae940255b47946a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on train dataset #3:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c307733549414459aeced7281723e123"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Validation Dataset**","metadata":{}},{"cell_type":"code","source":"eval_dataset = raw_datasets[\"validation\"]\neval_dataset = eval_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on Validation dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:22:53.492327Z","iopub.execute_input":"2024-03-13T07:22:53.492732Z","iopub.status.idle":"2024-03-13T07:22:58.595359Z","shell.execute_reply.started":"2024-03-13T07:22:53.492697Z","shell.execute_reply":"2024-03-13T07:22:58.594288Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #0:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d323d53791424a01b337eb35c9b752f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #2:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"128e9432257f40d2ad00e620a064a5a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #1:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d7efaea50af4e63afcf5456fa7781eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #3:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac13a6febee8498e9cd5a99f3b4d207b"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:23:01.521029Z","iopub.execute_input":"2024-03-13T07:23:01.521469Z","iopub.status.idle":"2024-03-13T07:23:01.526854Z","shell.execute_reply.started":"2024-03-13T07:23:01.521429Z","shell.execute_reply":"2024-03-13T07:23:01.525754Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Metrics\nmetric = load_metric(\"seqeval\")\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    # Unpack nested dictionaries\n    final_results = {}\n    for key, value in results.items():\n        if isinstance(value, dict):\n            for n, v in value.items():\n                final_results[f\"{key}_{n}\"] = v\n        else:\n            final_results[key] = value\n    return final_results","metadata":{"execution":{"iopub.status.busy":"2024-03-13T07:23:04.963879Z","iopub.execute_input":"2024-03-13T07:23:04.964607Z","iopub.status.idle":"2024-03-13T07:23:05.438249Z","shell.execute_reply.started":"2024-03-13T07:23:04.964573Z","shell.execute_reply":"2024-03-13T07:23:05.437312Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a72f05f64391447aad07d80d54fbf381"}},"metadata":{}}]},{"cell_type":"code","source":"# args=TrainingArguments(output_dir='output_dir',max_steps=5)\n# args=TrainingArguments(\n#     output_dir='output_dir',\n#     per_device_train_batch_size=8,\n#     per_device_eval_batch_size=8,\n#     num_train_epochs=3)\nbatch_size=8\nargs=TrainingArguments(\n    output_dir='output_dir',\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    evaluation_strategy = \"epoch\",\n    learning_rate=4e-5)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:32:41.995286Z","iopub.execute_input":"2024-03-13T09:32:41.996034Z","iopub.status.idle":"2024-03-13T09:32:42.006663Z","shell.execute_reply.started":"2024-03-13T09:32:41.996000Z","shell.execute_reply":"2024-03-13T09:32:42.004962Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Initialize our Trainer\n# early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)\n# args.metric_for_best_model = \"f1\"\n# args.load_best_model_at_end = True\n# args.evaluation_strategy = IntervalStrategy.STEPS\n# args.eval_steps = args.save_steps\n# args.greater_is_better = True\n\ntrainer = Trainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    # callbacks=[early_stopping_callback],\n    args=args,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:32:45.729625Z","iopub.execute_input":"2024-03-13T09:32:45.730185Z","iopub.status.idle":"2024-03-13T09:32:45.931203Z","shell.execute_reply.started":"2024-03-13T09:32:45.730145Z","shell.execute_reply":"2024-03-13T09:32:45.929902Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.args","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:32:48.496596Z","iopub.execute_input":"2024-03-13T09:32:48.497420Z","iopub.status.idle":"2024-03-13T09:32:48.508562Z","shell.execute_reply.started":"2024-03-13T09:32:48.497385Z","shell.execute_reply":"2024-03-13T09:32:48.507461Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=2,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=None,\nevaluation_strategy=epoch,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=4e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=output_dir/runs/Mar13_09-32-41_79552e4623e9,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3,\noptim=adamw_torch,\noptim_args=None,\noutput_dir=output_dir,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=10,\nper_device_train_batch_size=10,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nresume_from_checkpoint=None,\nrun_name=output_dir,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=500,\nsave_strategy=steps,\nsave_total_limit=None,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=0,\nweight_decay=0.0,\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"**Training the Model**","metadata":{}},{"cell_type":"code","source":"train_result = trainer.train()\nmetrics = train_result.metrics","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:32:54.882449Z","iopub.execute_input":"2024-03-13T09:32:54.883132Z","iopub.status.idle":"2024-03-13T10:41:41.682906Z","shell.execute_reply.started":"2024-03-13T09:32:54.883085Z","shell.execute_reply":"2024-03-13T10:41:41.681829Z"},"trusted":true},"execution_count":84,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3000/3000 1:08:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Loc Precision</th>\n      <th>Loc Recall</th>\n      <th>Loc F1</th>\n      <th>Loc Number</th>\n      <th>Org Precision</th>\n      <th>Org Recall</th>\n      <th>Org F1</th>\n      <th>Org Number</th>\n      <th>Per Precision</th>\n      <th>Per Recall</th>\n      <th>Per F1</th>\n      <th>Per Number</th>\n      <th>Overall Precision</th>\n      <th>Overall Recall</th>\n      <th>Overall F1</th>\n      <th>Overall Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.073600</td>\n      <td>0.223459</td>\n      <td>0.807972</td>\n      <td>0.837560</td>\n      <td>0.822500</td>\n      <td>10213</td>\n      <td>0.664523</td>\n      <td>0.686389</td>\n      <td>0.675279</td>\n      <td>9786</td>\n      <td>0.796529</td>\n      <td>0.820874</td>\n      <td>0.808519</td>\n      <td>10568</td>\n      <td>0.758121</td>\n      <td>0.783394</td>\n      <td>0.770550</td>\n      <td>0.944361</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.054000</td>\n      <td>0.244642</td>\n      <td>0.810656</td>\n      <td>0.831293</td>\n      <td>0.820845</td>\n      <td>10213</td>\n      <td>0.659564</td>\n      <td>0.676885</td>\n      <td>0.668112</td>\n      <td>9786</td>\n      <td>0.788212</td>\n      <td>0.821253</td>\n      <td>0.804393</td>\n      <td>10568</td>\n      <td>0.754686</td>\n      <td>0.778388</td>\n      <td>0.766354</td>\n      <td>0.943884</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.037400</td>\n      <td>0.269991</td>\n      <td>0.805070</td>\n      <td>0.830216</td>\n      <td>0.817450</td>\n      <td>10213</td>\n      <td>0.648524</td>\n      <td>0.675761</td>\n      <td>0.661863</td>\n      <td>9786</td>\n      <td>0.788395</td>\n      <td>0.815102</td>\n      <td>0.801526</td>\n      <td>10568</td>\n      <td>0.748886</td>\n      <td>0.775542</td>\n      <td>0.761981</td>\n      <td>0.943076</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory output_dir/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory output_dir/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory output_dir/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory output_dir/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory output_dir/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory output_dir/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Validation Metrics(Precision,Recall and F1 Score)**","metadata":{}},{"cell_type":"code","source":"metrics = trainer.evaluate()\n\ntrainer.log_metrics(\"eval\", metrics)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:41:54.962401Z","iopub.execute_input":"2024-03-13T10:41:54.962998Z","iopub.status.idle":"2024-03-13T10:46:43.775236Z","shell.execute_reply.started":"2024-03-13T10:41:54.962968Z","shell.execute_reply":"2024-03-13T10:46:43.773846Z"},"trusted":true},"execution_count":85,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =        3.0\n  eval_LOC_f1             =     0.8174\n  eval_LOC_number         =      10213\n  eval_LOC_precision      =     0.8051\n  eval_LOC_recall         =     0.8302\n  eval_ORG_f1             =     0.6619\n  eval_ORG_number         =       9786\n  eval_ORG_precision      =     0.6485\n  eval_ORG_recall         =     0.6758\n  eval_PER_f1             =     0.8015\n  eval_PER_number         =      10568\n  eval_PER_precision      =     0.7884\n  eval_PER_recall         =     0.8151\n  eval_loss               =       0.27\n  eval_overall_accuracy   =     0.9431\n  eval_overall_f1         =      0.762\n  eval_overall_precision  =     0.7489\n  eval_overall_recall     =     0.7755\n  eval_runtime            = 0:04:48.79\n  eval_samples_per_second =     46.608\n  eval_steps_per_second   =       2.33\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"NER_model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:51:54.003160Z","iopub.execute_input":"2024-03-13T10:51:54.004256Z","iopub.status.idle":"2024-03-13T10:51:55.795140Z","shell.execute_reply.started":"2024-03-13T10:51:54.004217Z","shell.execute_reply":"2024-03-13T10:51:55.794087Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:51:56.766044Z","iopub.execute_input":"2024-03-13T10:51:56.766490Z","iopub.status.idle":"2024-03-13T10:51:56.843751Z","shell.execute_reply.started":"2024-03-13T10:51:56.766459Z","shell.execute_reply":"2024-03-13T10:51:56.842583Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/vocab.txt',\n 'tokenizer/added_tokens.json',\n 'tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# !zip -r file.zip /kaggle/working/NER_model","metadata":{"execution":{"iopub.status.busy":"2024-03-12T20:50:30.582337Z","iopub.execute_input":"2024-03-12T20:50:30.583065Z","iopub.status.idle":"2024-03-12T20:51:07.215917Z","shell.execute_reply.started":"2024-03-12T20:50:30.583030Z","shell.execute_reply":"2024-03-12T20:51:07.214794Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/NER_model/ (stored 0%)\n  adding: kaggle/working/NER_model/model.safetensors (deflated 7%)\n  adding: kaggle/working/NER_model/config.json (deflated 54%)\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_test_set = {}\n\ntokenized_test_set = raw_datasets['test'].map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on test dataset of language {0}\".format(lang),\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:52:02.039414Z","iopub.execute_input":"2024-03-13T10:52:02.040231Z","iopub.status.idle":"2024-03-13T10:52:02.846111Z","shell.execute_reply.started":"2024-03-13T10:52:02.040199Z","shell.execute_reply":"2024-03-13T10:52:02.844845Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d0a48cf025943bf96dfc30ca1eb6c6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fba4cb7cc0f04b68ae4a177f8fc3a973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46110e6c3f284cbcbb626f0289438fb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e8a419cfd7e4aebb3e5d17bbcc175bf"}},"metadata":{}}]},{"cell_type":"code","source":"final_metrics = {}\n\n\npredictions, labels, metrics = trainer.predict(tokenized_test_set, metric_key_prefix=lang)\n\nlang_specific_results = {}\nfor key in metrics:\n  if 'overall_precision' in key:\n    lang_specific_results['Precision'] = metrics[key]\n  elif 'overall_recall' in key:\n    lang_specific_results['Recall'] = metrics[key]\n  elif 'overall_f1' in key:\n    lang_specific_results['F1'] = metrics[key]\nfinal_metrics = lang_specific_results","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:52:06.367541Z","iopub.execute_input":"2024-03-13T10:52:06.367963Z","iopub.status.idle":"2024-03-13T10:52:25.591397Z","shell.execute_reply.started":"2024-03-13T10:52:06.367929Z","shell.execute_reply":"2024-03-13T10:52:25.590193Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"**Test_Set Metrics(Precision,Recall and F1-Score)**","metadata":{}},{"cell_type":"code","source":"print(final_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:07.242280Z","iopub.execute_input":"2024-03-13T10:53:07.243093Z","iopub.status.idle":"2024-03-13T10:53:07.250098Z","shell.execute_reply.started":"2024-03-13T10:53:07.243056Z","shell.execute_reply":"2024-03-13T10:53:07.248950Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"{'Precision': 0.7525374577090382, 'Recall': 0.807153965785381, 'F1': 0.7788894447223612}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"***Q.4***","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"ner_model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:10.684809Z","iopub.execute_input":"2024-03-13T10:53:10.685699Z","iopub.status.idle":"2024-03-13T10:53:12.083941Z","shell.execute_reply.started":"2024-03-13T10:53:10.685666Z","shell.execute_reply":"2024-03-13T10:53:12.082854Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\"NER_model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:13.641000Z","iopub.execute_input":"2024-03-13T10:53:13.641949Z","iopub.status.idle":"2024-03-13T10:53:13.952144Z","shell.execute_reply.started":"2024-03-13T10:53:13.641905Z","shell.execute_reply":"2024-03-13T10:53:13.950838Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"**Dataset of 25 sentences**","metadata":{}},{"cell_type":"code","source":"id2label = {\n    str(i): label for i,label in enumerate(label_list)\n}\nlabel2id = {\n    label: str(i) for i,label in enumerate(label_list)\n}\nprint(id2label)\nprint(label2id)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:16.464076Z","iopub.execute_input":"2024-03-13T10:53:16.464790Z","iopub.status.idle":"2024-03-13T10:53:16.474206Z","shell.execute_reply.started":"2024-03-13T10:53:16.464753Z","shell.execute_reply":"2024-03-13T10:53:16.472626Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"{'0': 'O', '1': 'B-PER', '2': 'I-PER', '3': 'B-ORG', '4': 'I-ORG', '5': 'B-LOC', '6': 'I-LOC'}\n{'O': '0', 'B-PER': '1', 'I-PER': '2', 'B-ORG': '3', 'I-ORG': '4', 'B-LOC': '5', 'I-LOC': '6'}\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nconfig=json.load(open(\"/kaggle/working/NER_model/config.json\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:18.387828Z","iopub.execute_input":"2024-03-13T10:53:18.388719Z","iopub.status.idle":"2024-03-13T10:53:18.395611Z","shell.execute_reply.started":"2024-03-13T10:53:18.388685Z","shell.execute_reply":"2024-03-13T10:53:18.394458Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"config[\"id2label\"] = id2label\nconfig[\"label2id\"] = label2id","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:19.318001Z","iopub.execute_input":"2024-03-13T10:53:19.318870Z","iopub.status.idle":"2024-03-13T10:53:19.324959Z","shell.execute_reply.started":"2024-03-13T10:53:19.318833Z","shell.execute_reply":"2024-03-13T10:53:19.323821Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"json.dump(config, open(\"/kaggle/working/NER_model/config.json\",\"w\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:21.754492Z","iopub.execute_input":"2024-03-13T10:53:21.755189Z","iopub.status.idle":"2024-03-13T10:53:21.762671Z","shell.execute_reply.started":"2024-03-13T10:53:21.755157Z","shell.execute_reply":"2024-03-13T10:53:21.761435Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\"NER_model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:22.999069Z","iopub.execute_input":"2024-03-13T10:53:22.999779Z","iopub.status.idle":"2024-03-13T10:53:23.916276Z","shell.execute_reply.started":"2024-03-13T10:53:22.999740Z","shell.execute_reply":"2024-03-13T10:53:23.915275Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nds={'tokens':[['मिशेल', 'ने', 'कहा', 'कि', 'मैं', 'यहां', 'सबसे', 'पहले', 'और', 'सबसे', 'आगे', 'हूं', ' ,', 'क्योंकि', 'हमें', 'राष्ट्रपति', 'पद', 'के', 'लिए', 'हमारी', 'दोस्त', 'हिलेरी', ' से', 'ज्यादा', 'योग्य', 'और', 'तैयार', 'उम्मीदवार', 'कभी', 'नहीं', 'मिला', '।'], ['उस', 'ताम्बे', 'की', 'परत', 'पे', 'जमे', 'परतों', 'के', 'जो', 'रंग', 'हैं', ','], ['सरकार', 'ने', 'हमें', 'अपने', 'हाल', 'पर', 'मरने', 'के', 'लिए', 'छोड़', 'दिया', 'है', '।'], ['इतना', 'ही', 'नहीं', 'उसने', 'पिछले', '2', 'वर्षों', 'में', '6', 'अन्य', 'महिलाओं', 'केसाथ', 'यौन', 'उत्पीड़न', 'भी', 'किया', '।'], ['राजे', 'छह', 'राज्यों', 'के', 'मुख्यमंत्रियों', 'के', 'साथ', 'नीति', 'आयोग', 'की', 'बैठक', 'में', 'भाग', 'लेने', 'दिल्ली', 'आईं', 'थी', '।'], ['क्रांतिदूत', 'आजादी', '/', 'विभाजन', 'पूर्व', 'के', 'वे', 'पन्द्रह', 'दिन', ' -', '१४', 'अगस्त', ',', '१९४७', '-', 'सुबह', '9', 'बजे', 'बना', 'पाकिस्तान', 'और', 'मध्यरात्रि', '12', 'बजे', 'भारत', 'हुआ', 'आजाद', ' -', 'प्रशांत', 'पोळ'], ['मप्र', 'हाईकोर्ट', 'ने', 'भोपाल', 'के', 'लिए', 'निर्धारित', 'बाजार', 'मूल्य', 'की', 'गाइड-लाइन', 'के', 'उस', 'प्रावधान', 'पर', 'पूर्व', 'में', 'लगायी', 'गई', 'रोक', 'बरकरार', 'रखी', 'है', ',', 'जिसके', 'तहत', 'फ्लैटों', 'की', 'बाजार', 'मूल्य', 'की', 'गणना', 'बिल्ट-अप', 'एरिया', 'व', 'सामान्य', 'सुविधाओं', 'को', 'शामिल', 'करते', 'हुए', 'की', 'जानी', 'थी', '।'], ['जब', 'मोदी', 'मजबूत', 'होंगे', 'तो', 'देश', 'भी', 'और', 'मजबूत', 'होगा', '।'], ['इस', 'आम', 'चुनाव', 'में', 'भाजपा', 'नेता', 'सतीश', 'कुमार', 'गौतम', 'को', 'सबसे', 'अधिक', '6', 'लाख', '56', 'हजार', '215', 'वोट', 'प्राप्त', 'हुए', '।'], ['.4)', 'देश', 'में', 'सभी', 'प्रकार', 'के', 'छोटे-बड़े', 'कृषि', ',', 'सेवा', ',', 'व्यापार', ',', 'उद्योग', 'का', 'पंजीकरण', 'तुरंत', 'अनिवार्य', 'होना', 'चाहिए', ',', 'साथ', 'उनको', 'रु', '1000', 'से', 'ऊपर', 'के', 'लेन', 'देन', 'को', 'ऑन', 'लाइन/', 'इलेक्ट्रॉनिक', 'माध्यम', 'से', 'करना', 'अनिवार्य', 'होना', 'चाहिये।'], ['निर्भया', 'के', 'परिजनों', 'ने', 'आवेदन', 'किया', 'है', 'कि', 'उन्हें', 'फांसी', 'दिए', 'जाने', 'के', 'समय', 'उस', 'स्थान', 'पर', 'मौजूद', 'रहने', 'की', 'इजाजत', 'दी', 'जाए।'], ['कच्चे', 'माल', 'की', 'लागत', 'राजस्व', 'का', 'तकरीबन', '60', 'प्रतिशत', 'होती', 'है', 'और', 'दिसंबर', 'से', 'अप्रैल', 'के', 'बीच', 'इसमें', '25', 'प्रतिशत', 'तक', 'का', 'इजाफा', 'हो', 'चुका', 'है।'], ['उनका', 'अखबार', 'बंद', 'भले', 'हो', 'गया', 'पर', 'भाषा', 'पर', 'सरकारी', 'मोहर', 'लग', 'चुकी', 'है।'], ['इस', 'पर', 'सेना', 'की', '14', 'राष्ट्रीय', 'राइफल्स', ',', 'जम्मू-कश्मीर', 'पुलिस', 'के', 'स्पेशल', 'ऑपरेशन', 'ग्रुप', 'और', 'केंद्रीय', 'रिजर्व', 'पुलिस', 'बल', 'के', 'जवानों', 'ने', 'जंगलों', 'की', 'घेराबंदी', 'कर', 'तलाशी', 'अभियान', 'शुरू', 'किया।'], ['.कट्टर', 'सेक्स', ',', 'बिग', 'डिक', ',', 'बड़ी', 'डिक्स', ',', 'उसे', 'बिल्ली', 'गड़बड़', 'हो', 'रही', 'है', ',', 'बड़े', 'स्तन', ',', 'बिल्ली', ',', 'उसे', 'बिल्ली', 'कुचल', ',', 'उसे', 'बिल्ली', 'पर', ',', 'उसे', 'बिल्ली', 'गड़बड़', 'हो', ',', 'get', 'ur', 'pussy', 'wet', 'porn', ',', 'सभी', 'उसे', 'pussi', 'अश्लील', ',', 'लड़की', 'अपने', 'पैर', 'की', 'उंगलियों', 'चूसना', 'हो', 'जाता', 'है।'], ['आज', 'की', 'तारीख', 'है', '10', 'अगस्त', '2018', 'तथा', 'आज', 'इस', 'वर्ष', 'का', '222वां', 'दिन', 'है।', 'इन', '222', 'दिनों', 'में', 'प्रारंग', 'अपने', 'परिवार', 'के', 'जौनपुरवासियों', 'तक', '208', 'लेख', 'पहुंचा', 'चुका', 'है', 'तथा', 'यह', 'लेख', '209वां', 'लेख', 'होगा।'], ['वहीं', 'प्रबंधन', 'समिति', 'कुसुम', 'चाचान', 'कहतीं', 'हैं', 'कि', 'मरीजों', 'एवं', 'उनके', 'स्वजनों', 'को', 'निशुल्क', 'भोजन', 'कराकर', 'सुख', 'की', 'अनुभूति', 'होती', 'है।'], ['स्थिर', 'दर', 'को', 'पांच', 'से', '10', 'साल', 'के', 'लिए', 'निश्चित', 'रखा', 'जा', 'सकता', 'है', 'और', 'उसके', 'बाद', 'वह', 'परिवर्तनशील', 'ब्याज', 'दर', 'की', 'श्रेणी', 'में', 'आ', 'जाएगा।'], ['इस', 'सर्वेक्षण', 'में', 'छोटे', 'स्तर', 'की', '49', 'फीसदी', 'इकाइयां', ',', '35', 'फीसदी', 'मझोली', 'इकाइयां', 'और', '16', 'फीसदी', 'बड़ी', 'इकाइयां', 'शामिल', 'हुईं।'], ['सामाजिक', 'संस्थाओं', 'व', 'आप', 'कार्यकर्ताओं', 'ने', 'नगरपालिका', 'के', 'खिलाफ', 'जमकर', 'नारेबाजी', 'की', '।'], ['संघ', 'के', 'प्रांतीय', 'सचिव', 'एवं', 'कोषाध्यक्ष', 'रणदीप', 'आर्य', 'ने', 'बताया', 'कि', 'बिजली', 'विभाग', 'में', 'कभी', 'ट्रांसफार्मर', 'दिलवाने', 'के', 'नाम', 'पर', 'और', 'कभी', 'तेल', 'व', 'केबल', 'के', 'नाम', 'पर', 'अतिरिक्त', 'शुल्क', 'मांगा', 'जाता', 'है', 'और', 'किसान', 'को', 'मजबूरीवश', 'यह', 'शुल्क', 'देना', 'पड़ता', 'है', '।'], ['मुरादाबाद', '/', 'सिपाही', 'ने', 'कैंटीन', 'में', 'खड़े', 'लोगों', 'को', 'डंडों', 'से', 'पीटा', ',', 'रिश्वत', 'भी', 'मांगी'], ['जी', 'हां', 'विश्व', 'का', 'पहला', 'वजाइना', 'म्यूजियम', 'लंदन', 'में', 'खुलने', 'जा', 'रहा', 'है।'], ['टॉयलेट', 'एक', 'कथा', '', 'बिलासपुर', 'की', 'लड़की', 'ने', 'शादी', 'से', 'इनकार', 'किया', 'तब', 'युवक', 'ने', 'बनवाया', 'टॉयलेट', ',', 'दिल्ली', 'की', 'टीम', 'ने', 'द', '|'], ['राजीव', 'गांधी', 'उर्फ', 'बॉबी', 'ने', 'बताया', 'कि', 'विरोध', 'पर', 'नगर', 'निगम', 'ने', 'टावर', 'की', 'स्वीकृति', 'रद्द', 'कर', 'दी', 'थी', '।']]\n    ,'ner_tags':[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 5, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 1, 2], [5, 6, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 3, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 3, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0], [1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n    \nds = Dataset.from_dict(ds)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:25.927247Z","iopub.execute_input":"2024-03-13T10:53:25.927766Z","iopub.status.idle":"2024-03-13T10:53:26.002075Z","shell.execute_reply.started":"2024-03-13T10:53:25.927733Z","shell.execute_reply":"2024-03-13T10:53:26.000940Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"tokenized_test_set = {}\n\ntokenized_test_set = ds.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=32,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on test dataset of language {0}\".format(lang),\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:27.794945Z","iopub.execute_input":"2024-03-13T10:53:27.795822Z","iopub.status.idle":"2024-03-13T10:53:30.496018Z","shell.execute_reply.started":"2024-03-13T10:53:27.795786Z","shell.execute_reply":"2024-03-13T10:53:30.494763Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"                            ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca3b3ca3d6e4914a0a8752036539a97"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f102ffd86cc24a6797d4898ba552152c"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f564b4eeafc4d12865cc65d4a4d1375"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6869a59bcb4447a1b68e73b1d6265a56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dd55b4d3d7f42eeab3e8529fb421fd8"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73674b99e03249c393e86a6941838800"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec3a73b3f5f4f8180a2e87030878116"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6b1262f79444bde8578719afc2d6845"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #8:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a829af9e0524be4a41308335a79a814"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #9:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94011e928d443dd879b7609997818a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #10:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"502b64681c6d4088985037a98ab50d26"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #11:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e7e2f426f64ae9ade1fe8af462904c"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #12:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6811b0fcff7545928c6af35ac343fc44"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #13:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc10d5480bd4ea1b3391ae3dea69b2d"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #14:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81a4e897160f416e96a4d8b89b824739"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #15:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2deeaf42a22e4982af998c6ccd75222a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #16:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d4d0339a75640f29c0fac7e4cc4ae51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #17:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38ffb485e12c49c69acf80e6039fade1"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #18:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2290bfe2bd4e49b046a149e26adb3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #19:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d6d6eab2d244aa992e6c950f6cddef2"}},"metadata":{}},{"name":"stdout","text":"   ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #21:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33179bd2cba047a1aae33fdfc0666f76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #20:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"842dc3f12c854b02a8c9cec93e5a197e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #22:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9147dff3930f4cc8b8f5e7ad8d99336d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #23:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6b1deb6b4734fd9ba26be8ff9562fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #24:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a16f487b5440d1aa1360ab04a65715"}},"metadata":{}}]},{"cell_type":"code","source":"final_metrics = {}\n\n\npredictions, labels, metrics = trainer.predict(tokenized_test_set, metric_key_prefix=lang)\n\nlang_specific_results = {}\nfor key in metrics:\n  if 'overall_precision' in key:\n    lang_specific_results['Precision'] = metrics[key]\n  elif 'overall_recall' in key:\n    lang_specific_results['Recall'] = metrics[key]\n  elif 'overall_f1' in key:\n    lang_specific_results['F1'] = metrics[key]\nfinal_metrics = lang_specific_results","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:33.951519Z","iopub.execute_input":"2024-03-13T10:53:33.951917Z","iopub.status.idle":"2024-03-13T10:53:34.635137Z","shell.execute_reply.started":"2024-03-13T10:53:33.951882Z","shell.execute_reply":"2024-03-13T10:53:34.633932Z"},"trusted":true},"execution_count":100,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"markdown","source":"**25 Sentences Metric(Precision,Recall,F1-Score)**","metadata":{}},{"cell_type":"code","source":"print(final_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:38.431806Z","iopub.execute_input":"2024-03-13T10:53:38.432450Z","iopub.status.idle":"2024-03-13T10:53:38.439782Z","shell.execute_reply.started":"2024-03-13T10:53:38.432416Z","shell.execute_reply":"2024-03-13T10:53:38.438674Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"{'Precision': 0.5555555555555556, 'Recall': 0.625, 'F1': 0.5882352941176471}\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_predictions( sentence, tokenizer, model ):\n  # Let us first tokenize the sentence - split words into subwords\n  tok_sentence = tokenizer(sentence, return_tensors='pt')\n\n  with torch.no_grad():\n    # we will send the tokenized sentence to the model to get predictions\n    logits = model(**tok_sentence).logits.argmax(-1)\n    \n    # We will map the maximum predicted class id with the class label\n    predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n    \n    predicted_labels = []\n    \n    previous_token_id = 0\n    # we need to assign the named entity label to the head word and not the following sub-words\n    word_ids = tok_sentence.word_ids()\n    for word_index in range(len(word_ids)):\n        if word_ids[word_index] == None:\n            previous_token_id = word_ids[word_index]\n        elif word_ids[word_index] == previous_token_id:\n            previous_token_id = word_ids[word_index]\n        else:\n            predicted_labels.append( predicted_tokens_classes[ word_index ] )\n            previous_token_id = word_ids[word_index]\n    \n    return predicted_labels","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:41.744995Z","iopub.execute_input":"2024-03-13T10:53:41.745609Z","iopub.status.idle":"2024-03-13T10:53:41.754728Z","shell.execute_reply.started":"2024-03-13T10:53:41.745576Z","shell.execute_reply":"2024-03-13T10:53:41.753572Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"**Tokenization of 25 Sentences**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n\n\nsentences=['मिशेल ने कहा कि मैं यहां सबसे पहले और सबसे आगे हूं, क्योंकि हमें राष्ट्रपति पद के लिए हमारी दोस्त हिलेरी से ज्यादा योग्य और तैयार उम्मीदवार कभी नहीं मिला।',\n           'उस ताम्बे की परत पे जमे परतों के जो रंग हैं,',\n           'सरकार ने हमें अपने हाल पर मरने के लिए छोड़ दिया है।',\n           'इतना ही नहीं उसने पिछले 2 वर्षों में 6 अन्य महिलाओं केसाथ यौन उत्पीड़न भी किया।',\n           'राजे छह राज्यों के मुख्यमंत्रियों के साथ नीति आयोग की बैठक में भाग लेने दिल्ली आईं थी।',\n           'क्रांतिदूत: आजादी / विभाजन पूर्व के वे पन्द्रह दिन - १४ अगस्त, १९४७ - सुबह 9 बजे बना पाकिस्तान और मध्यरात्रि 12 बजे भारत हुआ आजाद - प्रशांत पोळ',\n           'मप्र हाईकोर्ट ने भोपाल के लिए निर्धारित बाजार मूल्य की गाइड-लाइन के उस प्रावधान पर पूर्व में लगायी गई रोक बरकरार रखी है, जिसके तहत फ्लैटों की बाजार मूल्य की गणना बिल्ट-अप एरिया व सामान्य सुविधाओं को शामिल करते हुए की जानी थी।',\n           'जब मोदी मजबूत होंगे तो देश भी और मजबूत होगा।',\n           'इस आम चुनाव में भाजपा नेता सतीश कुमार गौतम को सबसे अधिक 6 लाख 56 हजार 215 वोट प्राप्त हुए.',\n           '4) देश में सभी प्रकार के छोटे-बड़े कृषि, सेवा, व्यपार,उद्योग का पंजीकरण तुरंत अनिवार्य होना चाहिए, साथ उनको रु 1000 से ऊपर के लेन देन को ऑन लाइन/ इलेक्ट्रॉनिक माध्यम से करना अनिवार्य होना चाहिये।',\n           'निर्भया के परिजनों ने आवेदन किया है कि उन्हें फांसी दिए जाने के समय उस स्थान पर मौजूद रहने की इजाजत दी जाए।',\n           'कच्चे माल की लागत राजस्व का तकरीबन 60 प्रतिशत होती है और दिसंबर से अप्रैल के बीच इसमें 25 प्रतिशत तक का इजाफा हो चुका है।',\n           'उनका अखबार बंद भले हो गया पर भाषा पर सरकारी मोहर लग चुकी है।',\n           'इस पर सेना की 14 राष्ट्रीय राइफल्स, जम्मू-कश्मीर पुलिस के स्पेशल ऑपरेशन ग्रुप और केंद्रीय रिजर्व पुलिस बल के जवानों ने जंगलों की घेराबंदी कर तलाशी अभियान शुरू किया।',\n           'कट्टर सेक्स, बिग डिक, बड़ी डिक्स, उसे बिल्ली गड़बड़ हो रही है, बड़े स्तन, बिल्ली, उसे बिल्ली कुचल, उसे बिल्ली पर, उसे बिल्ली गड़बड़ हो, get ur pussy wet porn, सभी उसे pussi अश्लील, लड़की अपने पैर की उंगलियों चूसना हो जाता है',\n           'आज की तारीख है 10 अगस्त 2018 तथा आज इस वर्ष का 222वां दिन है। इन 222 दिनों में प्रारंग अपने परिवार के जौनपुरवासियों तक 208 लेख पहुंचा चुका है तथा यह लेख 209वां लेख होगा।',\n           'वहीं प्रबंधन समिति कुसुम चाचान कहतीं हैं कि मरीजों एवं उनके स्वजनों को निशुल्क भोजन कराकर सुख की अनुभूति होती है।',\n           'स्थिर दर को पांच से 10 साल के लिए निश्चित रखा जा सकता है और उसके बाद वह परिवर्तनशील ब्याज दर की श्रेणी में आ जाएगा।',\n           'इस सर्वेक्षण में छोटे स्तर की 49 फीसदी इकाइयां, 35 फीसदी मझोली इकाइयां और 16 फीसदी बड़ी इकाइयां शामिल हुईं।',\n           'सामाजिक संस्थाओं व आप कार्यकर्ताओं ने नगरपालिका के खिलाफ जमकर नारेबाजी की।',\n        'संघ के प्रांतीय सचिव एवं कोषाध्यक्ष रणदीप आर्य ने बताया कि बिजली विभाग में कभी ट्रांसफार्मर दिलवाने के नाम पर और कभी तेल व केबल के नाम पर अतिरिक्त शुल्क मांगा जाता है और किसान को मजबूरीवश यह शुल्क देना पड़ता है।',\n           'मुरादाबाद / सिपाही ने कैंटीन में खड़े लोगों को डंडों से पीटा, रिश्वत भी मांगी',\n           'जी हां विश्व का पहला वजाइना म्यूजियम लंदन में खुलने जा रहा है।',\n           'टॉयलेट एक कथा: बिलासपुर की लड़की ने शादी से इनकार किया तब युवक ने बनवाया टॉयलेट, दिल्ली की टीम ने द  |',\n           'राजीव गांधी उर्फ बॉबी ने बताया कि विरोध पर नगर निगम ने टावर की स्वीकृति रद्द कर दी थी।']\nIndic_NER=[]\nfor sentence in sentences:\n    predicted_labels = get_predictions(sentence=sentence, \n                                   tokenizer=tokenizer,\n                                   model=model\n                                   )\n    Indic_NER.append(predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:46.240005Z","iopub.execute_input":"2024-03-13T10:53:46.240364Z","iopub.status.idle":"2024-03-13T10:53:48.613486Z","shell.execute_reply.started":"2024-03-13T10:53:46.240333Z","shell.execute_reply":"2024-03-13T10:53:48.611529Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"**Predicted Labels for 25 Sentences**","metadata":{}},{"cell_type":"code","source":"print(Indic_NER)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:53:53.237291Z","iopub.execute_input":"2024-03-13T10:53:53.238267Z","iopub.status.idle":"2024-03-13T10:53:53.248355Z","shell.execute_reply.started":"2024-03-13T10:53:53.238221Z","shell.execute_reply":"2024-03-13T10:53:53.246938Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"[['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O'], ['O', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-PER', 'O'], ['B-ORG', 'I-ORG', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'B-ORG', 'O', 'O', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'B-PER', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Ground_truth and Predicted Labels**","metadata":{}},{"cell_type":"code","source":"ground_truth='''\nमिशेल:B-PER;ने:O;कहा:O;कि:O;मैं:O;यहां:O;सबसे:O;पहले:O;और:O;सबसे:O;आगे:O;हूं:O; ,:O;क्योंकि:O;हमें:O;राष्ट्रपति:B-MISC;पद:O;के:O;लिए:O;हमारी:O;दोस्त:O;हिलेरी:B-PER; से:O;ज्यादा:O;योग्य:O;और:O;तैयार:O;उम्मीदवार:O;कभी:O;नहीं:O;मिला:O;।:O;\n\n\nउस:O;ताम्बे:B-MISC;की:O;परत:O;पे:O;जमे:O;परतों:O;के:O;जो:O;रंग:O;हैं:O;,:O\n\n\nसरकार:O;ने:O;हमें:O;अपने:O;हाल:O;पर:O;मरने:O;के:O;लिए:O;छोड़:O;दिया:O;है:O;।:O\n\n\nइतना:O;ही:O;नहीं:O;उसने:O;पिछले:O;2:B-MISC;वर्षों:O;में:O;6:B-MISC;अन्य:O;महिलाओं:O;केसाथ:O;यौन:O;उत्पीड़न:O;भी:O;किया:O;।:O\n\n\nराजे:B-PER;छह:B-MISC;राज्यों:O;के:O;मुख्यमंत्रियों:O;के:O;साथ:O;नीति:B-ORG;आयोग:I-ORG;की:O;बैठक:O;में:O;भाग:O;लेने:O;दिल्ली:B-LOC;आईं:O;थी:O;।:O\n\n\nक्रांतिदूत:B-ORG;आजादी:O;/:O;विभाजन:O;पूर्व:O;के:O;वे:O;पन्द्रह:B-MISC;दिन:O; -:O;१४:B-MISC;अगस्त:I-MISC;,:O;१९४७:I-MISC;-:O;सुबह:O;9:B-MISC;बजे:O;बना:O;पाकिस्तान:B-LOC;और:O;मध्यरात्रि:O;12:B-MISC;बजे:O;भारत:B-LOC;हुआ:O;आजाद:O; -:O;प्रशांत:B-PER;पोळ:I-PER\n\n\nमप्र:B-LOC;हाईकोर्ट:I-LOC;ने:O;भोपाल:B-LOC;के:O;लिए:O;निर्धारित:O;बाजार:O;मूल्य:O;की:O;गाइड-लाइन:O;के:O;उस:O;प्रावधान:O;पर:O;पूर्व:O;में:O;लगायी:O;गई:O;रोक:O;बरकरार:O;रखी:O;है:O;,:O;जिसके:O;तहत:O;फ्लैटों:O;की:O;बाजार:O;मूल्य:O;की:O;गणना:O;बिल्ट-अप:O;एरिया:O;व:O;सामान्य:O;सुविधाओं:O;को:O;शामिल:O;करते:O;हुए:O;की:O;जानी:O;थी:O;।:O\n\n\nजब:O;मोदी:B-PER;मजबूत:O;होंगे:O;तो:O;देश:O;भी:O;और:O;मजबूत:O;होगा:O;।:O\n\n\nइस:O;आम:O;चुनाव:O;में:O;भाजपा:B-ORG;नेता:O;सतीश:B-PER;कुमार:I-PER;गौतम:I-PER;को:O;सबसे:O;अधिक:O;6:B-MISC;लाख:I-MISC;56:I-MISC;हजार:I-MISC;215:I-MISC;वोट:O;प्राप्त:O;हुए:O;।:O\n\n\n.4):O;देश:O;में:O;सभी:O;प्रकार:O;के:O;छोटे-बड़े:O;कृषि:O;,:O;सेवा:O;,:O;व्यापार:O;,:O;उद्योग:O;का:O;पंजीकरण:O;तुरंत:O;अनिवार्य:O;होना:O;चाहिए:O;,:O;साथ:O;उनको:O;रु:O;1000:B-MISC;से:O;ऊपर:O;के:O;लेन:O;देन:O;को:O;ऑन:O;लाइन/:O;इलेक्ट्रॉनिक:O;माध्यम:O;से:O;करना:O;अनिवार्य:O;होना:O;चाहिये।:O\n\n\nनिर्भया:B-PER;के:O;परिजनों:O;ने:O;आवेदन:O;किया:O;है:O;कि:O;उन्हें:O;फांसी:O;दिए:O;जाने:O;के:O;समय:O;उस:O;स्थान:O;पर:O;मौजूद:O;रहने:O;की:O;इजाजत:O;दी:O;जाए।:O\n\n\nकच्चे:O;माल:O;की:O;लागत:O;राजस्व:O;का:O;तकरीबन:O;60:B-MISC;प्रतिशत:O;होती:O;है:O;और:O;दिसंबर:B-MISC;से:O;अप्रैल:B-MISC;के:O;बीच:O;इसमें:O;25:O;प्रतिशत:O;तक:O;का:O;इजाफा:O;हो:O;चुका:O;है।:O\n\n\nउनका:O;अखबार:O;बंद:O;भले:O;हो:O;गया:O;पर:O;भाषा:O;पर:O;सरकारी:O;मोहर:O;लग:O;चुकी:O;है।:O\n\n\nइस:O;पर:O;सेना:O;की:O;14:B-ORG;राष्ट्रीय:I-ORG;राइफल्स:I-ORG;,:O;जम्मू-कश्मीर:B-LOC;पुलिस:O;के:O;स्पेशल:O;ऑपरेशन:O;ग्रुप:O;और:O;केंद्रीय:B-ORG;रिजर्व:B-ORG;पुलिस:B-ORG;बल:B-ORG;के:O;जवानों:O;ने:O;जंगलों:O;की:O;घेराबंदी:O;कर:O;तलाशी:O;अभियान:O;शुरू:O;किया।:O\n\n\n.कट्टर:O;सेक्स:O;,:O;बिग:O;डिक:O;,:O;बड़ी:O;डिक्स:O;,:O;उसे:O;बिल्ली:O;गड़बड़:O;हो:O;रही:O;है:O;,:O;बड़े:O;स्तन:O;,:O;बिल्ली:O;,:O;उसे:O;बिल्ली:O;कुचल:O;,:O;उसे:O;बिल्ली:O;पर:O;,:O;उसे:O;बिल्ली:O;गड़बड़:O;हो:O;,:O;get:O;ur:O;pussy:O;wet:O;porn:O;,:O;सभी:O;उसे:O;pussi:O;अश्लील:O;,:O;लड़की:O;अपने:O;पैर:O;की:O;उंगलियों:O;चूसना:O;हो:O;जाता:O;है।:O\n\n\nआज:O;की:O;तारीख:O;है:O;10:B-MISC;अगस्त:I-MISC;2018:I-MISC;तथा:O;आज:O;इस:O;वर्ष:O;का:O;222वां:B-MISC;दिन:O;है।:O;इन:O;222:B-MISC;दिनों:O;में:O;प्रारंग:B-ORG;अपने:O;परिवार:O;के:O;जौनपुरवासियों:O;तक:O;208:B-MISC;लेख:O;पहुंचा:O;चुका:O;है:O;तथा:O;यह:O;लेख:O;209वां:B-MISC;लेख:O;होगा।:O\n\n\nवहीं:O;प्रबंधन:B-MISC;समिति:B-MISC;कुसुम:B-PER;चाचान:I-PER;कहतीं:O;हैं:O;कि:O;मरीजों:O;एवं:O;उनके:O;स्वजनों:O;को:O;निशुल्क:O;भोजन:O;कराकर:O;सुख:O;की:O;अनुभूति:O;होती:O;है।:O\n\n\nस्थिर:O;दर:O;को:O;पांच:B-MISC;से:O;10:B-MISC;साल:O;के:O;लिए:O;निश्चित:O;रखा:O;जा:O;सकता:O;है:O;और:O;उसके:O;बाद:O;वह:O;परिवर्तनशील:O;ब्याज:O;दर:O;की:O;श्रेणी:O;में:O;आ:O;जाएगा।:O\n\n\nइस:O;सर्वेक्षण:O;में:O;छोटे:O;स्तर:O;की:O;49:B-MISC;फीसदी:O;इकाइयां:O;,:O;35:B-MISC;फीसदी:O;मझोली:O;इकाइयां:O;और:O;16:B-MISC;फीसदी:O;बड़ी:O;इकाइयां:O;शामिल:O;हुईं।:O\n\n\nसामाजिक:O;संस्थाओं:O;व:O;आप:B-ORG;कार्यकर्ताओं:O;ने:O;नगरपालिका:B-ORG;के:O;खिलाफ:O;जमकर:O;नारेबाजी:O;की:O;।:O\n\n\nसंघ:O;के:O;प्रांतीय:B-MISC;सचिव:B-MISC;एवं:O;कोषाध्यक्ष:B-MISC;रणदीप:B-PER;आर्य:I-PER;ने:O;बताया:O;कि:O;बिजली:O;विभाग:O;में:O;कभी:O;ट्रांसफार्मर:O;दिलवाने:O;के:O;नाम:O;पर:O;और:O;कभी:O;तेल:O;व:O;केबल:O;के:O;नाम:O;पर:O;अतिरिक्त:O;शुल्क:O;मांगा:O;जाता:O;है:O;और:O;किसान:O;को:O;मजबूरीवश:O;यह:O;शुल्क:O;देना:O;पड़ता:O;है:O;।:O\n\n\nमुरादाबाद:B-LOC;/:O;सिपाही:O;ने:O;कैंटीन:O;में:O;खड़े:O;लोगों:O;को:O;डंडों:O;से:O;पीटा:O;,:O;रिश्वत:O;भी:O;मांगी:O\n\n\nजी:O;हां:O;विश्व:O;का:O;पहला:O;वजाइना:B-MISC;म्यूजियम:B-MISC;लंदन:B-LOC;में:O;खुलने:O;जा:O;रहा:O;है।:O\n\n\nटॉयलेट:B-MISC;एक:I-MISC;कथा:I-MISC;:O;बिलासपुर:B-LOC;की:O;लड़की:O;ने:O;शादी:O;से:O;इनकार:O;किया:O;तब:O;युवक:O;ने:O;बनवाया:O;टॉयलेट:O;,:O;दिल्ली:B-LOC;की:O;टीम:O;ने:O;द:O;|:O\n\n\nराजीव:B-PER;गांधी:I-PER;उर्फ:O;बॉबी:B-PER;ने:O;बताया:O;कि:O;विरोध:O;पर:O;नगर:O;निगम:O;ने:O;टावर:O;की:O;स्वीकृति:O;रद्द:O;कर:O;दी:O;थी:O;।:O\n\n'''\nIndic_NER=[['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O'], ['O', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-PER', 'O'], ['B-ORG', 'I-ORG', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'B-ORG', 'O', 'O', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'I-PER', 'O', 'B-PER', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T12:50:42.885292Z","iopub.execute_input":"2024-03-13T12:50:42.885623Z","iopub.status.idle":"2024-03-13T12:50:42.909981Z","shell.execute_reply.started":"2024-03-13T12:50:42.885598Z","shell.execute_reply":"2024-03-13T12:50:42.909014Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Preprocessing ground truth and Predicted Labels**","metadata":{}},{"cell_type":"code","source":"truth=[]\ntokens=[]\nground_truth=ground_truth.split('\\n')\nfor sentence in ground_truth:\n    temp=sentence.split(';')\n    temp2=[]\n    temp3=[]\n    for words in temp:\n        temp1=words.split(':')\n        if len(temp1)<2:continue\n        temp2.append(temp1[1])\n        temp3.append(temp1[0])\n    if len(temp2)>0:\n        truth.append(temp2)\n    if len(temp3)>0:tokens.append(temp3)\n# for sentence in Indic_NER:\n#     for i in range(len(sentence)):\n#         if(sentence[i]=='B-LOC'): sentence[i]='O'\n#         if(sentence[i]=='B-ORG'): sentence[i]='B-PER'\n#         if(sentence[i]=='B-PER'): sentence[i]='I-PER'\n#         if(sentence[i]=='I-LOC'): sentence[i]='B-ORG'\n#         if(sentence[i]=='I-PER'): sentence[i]='B-LOC'\n#         if(sentence[i]=='I-ORG'): sentence[i]='I-LOC' ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T12:50:45.663987Z","iopub.execute_input":"2024-03-13T12:50:45.664560Z","iopub.status.idle":"2024-03-13T12:50:45.671543Z","shell.execute_reply.started":"2024-03-13T12:50:45.664531Z","shell.execute_reply":"2024-03-13T12:50:45.670287Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Calculating Metrics**","metadata":{}},{"cell_type":"code","source":"def calculate_metrics(ground_truth, tokenizer_output):\n    true_positives=[0 for i in range(9)]\n    false_positives=[0 for i in range(9)]\n    false_negatives=[0 for i in range(9)]\n    for i in range (0, len(ground_truth)):\n        for j in range(len(ground_truth[i])):\n            if ground_truth[i][j]==tokenizer_output[i][j]:\n                if ground_truth[i][j]=='B-PER':true_positives[0]+=1\n                elif ground_truth[i][j]=='I-PER':true_positives[1]+=1\n                elif ground_truth[i][j]=='B-LOC':true_positives[2]+=1\n                elif ground_truth[i][j]=='I-LOC':true_positives[3]+=1\n                elif ground_truth[i][j]=='B-ORG':true_positives[4]+=1\n                elif ground_truth[i][j]=='I-ORG':true_positives[5]+=1\n                elif ground_truth[i][j]=='B-MISC':true_positives[6]+=1\n                elif ground_truth[i][j]=='I-MISC':true_positives[7]+=1\n                else:true_positives[8]+=1\n            else:\n                if ground_truth[i][j]=='B-PER':false_positives[0]+=1\n                elif ground_truth[i][j]=='I-PER':false_positives[1]+=1\n                elif ground_truth[i][j]=='B-LOC':false_positives[2]+=1\n                elif ground_truth[i][j]=='I-LOC':false_positives[3]+=1\n                elif ground_truth[i][j]=='B-ORG':false_positives[4]+=1\n                elif ground_truth[i][j]=='I-ORG':false_positives[5]+=1\n                elif ground_truth[i][j]=='B-MISC':false_positives[6]+=1\n                elif ground_truth[i][j]=='I-MISC':false_positives[7]+=1\n                else:false_positives[8]+=1\n\n                if ground_truth[i][j]=='B-PER':false_negatives[0]+=1\n                elif ground_truth[i][j]=='I-PER':false_negatives[1]+=1\n                elif ground_truth[i][j]=='B-LOC':false_negatives[2]+=1\n                elif ground_truth[i][j]=='I-LOC':false_negatives[3]+=1\n                elif ground_truth[i][j]=='B-ORG':false_negatives[4]+=1\n                elif ground_truth[i][j]=='I-ORG':false_negatives[5]+=1\n                elif ground_truth[i][j]=='B-MISC':false_negatives[6]+=1\n                elif ground_truth[i][j]=='I-MISC':false_negatives[7]+=1\n                else:false_negatives[8]+=1\n                \n    f_score=[0 for i in range(9)]\n    precision=[0 for i in range(9)]\n    recall=[0 for i in range(9)]\n    for i in range(9):\n        t_p=true_positives[i]\n        f_p=false_positives[i]\n        f_n=false_negatives[i]    \n        if t_p + f_p != 0:\n            precision[i] = t_p / (t_p + f_p) \n        else: precision[i] = 0\n        if t_p + f_n != 0:\n            recall[i] = t_p / (t_p + f_n)  \n        else:recall[i] =  0\n        if precision[i] + recall[i] != 0:\n            f_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])  \n        else:f_score[i] =  0\n    return f_score,precision,recall","metadata":{"execution":{"iopub.status.busy":"2024-03-13T12:53:08.172377Z","iopub.execute_input":"2024-03-13T12:53:08.172673Z","iopub.status.idle":"2024-03-13T12:53:08.188330Z","shell.execute_reply.started":"2024-03-13T12:53:08.172651Z","shell.execute_reply":"2024-03-13T12:53:08.187364Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Metrics for each class and Macro_F1-Score**","metadata":{}},{"cell_type":"code","source":"fscore_NER,precision_NER,recall_NER=calculate_metrics(truth,Indic_NER)\ntags=['B-PER','I-PER','B-LOC','I-LOC','B-ORG','I-ORG','B-MISC','I-MISC','Other']\nfor i in range(9):\n    print(\"Precision of \",tags[i],\" - \",precision_NER[i])\n    print(\"Recall of \",tags[i],\" - \",recall_NER[i])\n    print(\"F-Score of \",tags[i],\" - \",fscore_NER[i])\nMacro_F1_Score=0\nfor i in fscore_NER:\n    Macro_F1_Score+=i\nMacro_F1_Score=Macro_F1_Score/9\nprint(\"Macro_F1_Score - \",Macro_F1_Score)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T12:53:15.339414Z","iopub.execute_input":"2024-03-13T12:53:15.339731Z","iopub.status.idle":"2024-03-13T12:53:15.348116Z","shell.execute_reply.started":"2024-03-13T12:53:15.339708Z","shell.execute_reply":"2024-03-13T12:53:15.346637Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Precision of  B-PER  -  0.8181818181818182\nRecall of  B-PER  -  0.8181818181818182\nF-Score of  B-PER  -  0.8181818181818182\nPrecision of  I-PER  -  0.6666666666666666\nRecall of  I-PER  -  0.6666666666666666\nF-Score of  I-PER  -  0.6666666666666666\nPrecision of  B-LOC  -  0.6\nRecall of  B-LOC  -  0.6\nF-Score of  B-LOC  -  0.6\nPrecision of  I-LOC  -  0.0\nRecall of  I-LOC  -  0.0\nF-Score of  I-LOC  -  0\nPrecision of  B-ORG  -  0.36363636363636365\nRecall of  B-ORG  -  0.36363636363636365\nF-Score of  B-ORG  -  0.36363636363636365\nPrecision of  I-ORG  -  0.6666666666666666\nRecall of  I-ORG  -  0.6666666666666666\nF-Score of  I-ORG  -  0.6666666666666666\nPrecision of  B-MISC  -  0.0\nRecall of  B-MISC  -  0.0\nF-Score of  B-MISC  -  0\nPrecision of  I-MISC  -  0.0\nRecall of  I-MISC  -  0.0\nF-Score of  I-MISC  -  0\nPrecision of  Other  -  0.9607476635514018\nRecall of  Other  -  0.9607476635514018\nF-Score of  Other  -  0.9607476635514018\nMacro_F1_Score -  0.45287768652254634\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Calculating Overall Metrics**","metadata":{}},{"cell_type":"code","source":"def calculate_metrics(ground_truth, tokenizer_output):\n    t_p=0.0\n    f_p=0.0\n    f_n=0.0\n    for i in range (0, len(ground_truth)):\n        t_p+=len(set(ground_truth[i]) & set(tokenizer_output[i]))\n        f_p+=len(set(tokenizer_output[i]) - set(ground_truth[i]))\n        f_n+=len(set(ground_truth[i]) - set(tokenizer_output[i]))\n    if t_p + f_p != 0:\n        precision = t_p / (t_p + f_p) \n    else: precision = 0\n    if t_p + f_n != 0:\n        recall = t_p / (t_p + f_n)  \n    else:recall =  0\n    if precision + recall != 0:\n        f_score = 2 * (precision * recall) / (precision + recall)  \n    else:f_score =  0\n    return precision, recall, f_score","metadata":{"execution":{"iopub.status.busy":"2024-03-13T12:54:14.269980Z","iopub.execute_input":"2024-03-13T12:54:14.270294Z","iopub.status.idle":"2024-03-13T12:54:14.278234Z","shell.execute_reply.started":"2024-03-13T12:54:14.270271Z","shell.execute_reply":"2024-03-13T12:54:14.276794Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"precision,recall,fscore=calculate_metrics(truth,Indic_NER)\nprint(\"Precision - \",precision)\nprint(\"Recall - \",recall)\nprint(\"F-Score - \",fscore)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T12:54:17.421877Z","iopub.execute_input":"2024-03-13T12:54:17.422403Z","iopub.status.idle":"2024-03-13T12:54:17.427789Z","shell.execute_reply.started":"2024-03-13T12:54:17.422375Z","shell.execute_reply":"2024-03-13T12:54:17.427106Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Precision -  0.8245614035087719\nRecall -  0.6351351351351351\nF-Score -  0.7175572519083969\n","output_type":"stream"}]}]}